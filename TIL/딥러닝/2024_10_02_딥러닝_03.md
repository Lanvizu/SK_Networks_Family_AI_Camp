# 합성곱 신경망의 구성 요소

## 합성곱
- 필터(커널)를 사용하여 입력 데이터를 스캔하며 특징 추출
- 이미지의 공간적 특성 유지
- 사용: 이미지의 특정 패턴 감지에 효과적

## 특성맵
- 합성곱 연산의 결과물
- 입력 이미지에서 감지된 특징 시각화
- 사용: 특정 특징의 위치와 강도 파악에 유용

## 케라스 합성곱 층
- Conv2D, MaxPooling2D, AveragePooling2D 등 제공
- 사용: 다양한 합성곱 연산 구현에 활용

## 패딩과 스트라이드
- 패딩: 입력 주변에 추가 픽셀 추가
- 스트라이드: 필터 이동 간격
- 사용: 출력 크기 조절과 모델 복잡도 제어

## 풀링
- 특성 맵의 크기 축소
- 최대 풀링: 영역 내 최대값 선택
- 평균 풀링: 영역 내 평균값 계산
- 사용: 최대 풀링은 주요 특징 강조, 평균 풀링은 전체적 특징 파악

## 합성곱 신경망의 전체 구조
1. 입력층: 원본 이미지 데이터 수신
2. 특징 추출기: 합성곱층과 풀링층의 조합
3. 분류기(완전 연결층): 추출된 특징 기반 최종 분류
4. 출력층: 최종 예측 결과 제공

사용: 이미지 분류, 객체 검출, 얼굴 인식 등 컴퓨터 비전 작업에 효과적

```python
import tensorflow as tf
from tensorflow.keras import layers

data = tf.keras.datasets.fashion_mnist.load_data()
X = data[0][0]
y = data[0][1]

X.shape, y.shape
# ((60000, 28, 28), (60000,))
```

```python
# 데이터 분할
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# mnn
mnn_model = tf.keras.Sequential()
mnn_model.add(layers.Flatten(input_shape=(28, 28)))
mnn_model.add(layers.Normalization())
mnn_model.add(layers.Dense(128, activation='relu'))
mnn_model.add(layers.BatchNormalization())
mnn_model.add(layers.Dense(10, activation='softmax'))
# 스케줄
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=10000,
    decay_rate=0.9
)
mnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
mnn_model.fit(X_train, y_train, epochs=10, validation_split=0.1)
mnn_model.evaluate(X_test, y_test)
```

![image](https://github.com/user-attachments/assets/17fe52ec-92a3-46d2-b79a-3e74cfaa8dcf)

```python
# CNN
# C-P-C-P-FC
cnn_model = tf.keras.Sequential()
cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
cnn_model.add(layers.MaxPooling2D((2, 2)))
cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))
cnn_model.add(layers.MaxPooling2D((2, 2)))
# FC
cnn_model.add(layers.Flatten())
cnn_model.add(layers.Normalization())
cnn_model.add(layers.Dense(64, activation='relu'))
cnn_model.add(layers.BatchNormalization())
cnn_model.add(layers.Dense(10, activation='softmax'))

# 스케줄
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=10000,
    decay_rate=0.9
)
cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cnn_model.fit(X_train, y_train, epochs=10, validation_split=0.1)
cnn_model.evaluate(X_test, y_test)
```

![image](https://github.com/user-attachments/assets/a26d893f-2ed6-4b2e-a996-4a672a24e1a0)

- acc가 개선된 것을 확인

-----

```python
# CIFAR10 - rgv 채널
# 직접 CNN 구현
# ResNet50 모델을 불러와서 전이학습

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers

# 데이터
data = tf.keras.datasets.cifar10.load_data()
X_train = data[0][0]
y_train = data[0][1]
X_test = data[1][0]
y_test = data[1][1]
X_train = X_train / 255.0
X_test = X_test / 255.0
```

```python
X_train.shape, y_train.shape, X_test.shape, y_test.shape
# ((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))
```

```python
# CNN
# C-P-C-P-FC
cnn_model = tf.keras.Sequential()
cnn_model.add(layers.Normalization(input_shape=(32, 32, 3)))
cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu'))
cnn_model.add(layers.MaxPooling2D((2, 2)))
cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))
cnn_model.add(layers.MaxPooling2D((2, 2)))
# FC
cnn_model.add(layers.Flatten())
cnn_model.add(layers.Dense(128, activation='relu'))
cnn_model.add(layers.BatchNormalization())
cnn_model.add(layers.Dense(10, activation='softmax'))

# 스케줄
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.01,
    decay_steps=10000,
    decay_rate=0.9
)

# 콜백
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
check_point = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)

cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cnn_model.fit(X_train, y_train, epochs=200, validation_split=0.1, batch_size= 64, callbacks=[early_stopping, check_point])
cnn_model.evaluate(X_test, y_test)
```

![image](https://github.com/user-attachments/assets/fff3c421-43a9-4116-be15-0feb5894b1aa)

-----

```python
# 실습2
!unzip '/content/drive/MyDrive/Colab Notebooks/encore/csv/cat_dog.zip'
```
```python
from glob import glob
import cv2
import numpy as np
import tensorflow as tf

jpg_files = glob('/content/training_set/**/*.jpg',recursive=True)
cv2.imread(jpg_files[0])
```

![image](https://github.com/user-attachments/assets/43bf84b6-25f3-4d6e-8633-373342de3cb2)

```python
train_dir = '/content/training_set/training_set'
# 라벨링 자동
train_dataset =  tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    image_size=(128,128),
    batch_size=32,
    shuffle=True,
    seed=42,
    validation_split=0.1,  # 검증데이터를 10% 사용
    subset='training',  # 훈련데이터를 사용
    label_mode='binary'
)
valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    image_size=(128,128),
    batch_size=32,
    shuffle=True,
    seed=42,
    validation_split=0.1,  # 검증데이터를 10% 사용
    subset='validation',  # 훈련데이터를 사용
    label_mode='binary'
)

test_dir = '/content/test_set/test_set'
test_dataset =  tf.keras.preprocessing.image_dataset_from_directory(
    test_dir,
    image_size=(128,128),
    batch_size=32,
    seed=42,
    label_mode='binary'
)
```

```python
img, label = next(iter(train_dataset))
print(img.shape, label.shape)
print(label[:5])
print(img[0].shape)

# (32, 128, 128, 3) (32, 1)
# tf.Tensor(
# [[0.]
#  [0.]
#  [0.]
#  [0.]
#  [1.]], shape=(5, 1), dtype=float32)
# (128, 128, 3)
```

```python
cnn_model = tf.keras.Sequential()
cnn_model.add(tf.keras.layers.Input(shape=(128, 128, 3)))
cnn_model.add(tf.keras.layers.Rescaling(1./255))
cnn_model.add(tf.keras.layers.Normalization())
# CNN
cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))
cnn_model.add(tf.keras.layers.MaxPooling2D((2, 2)))
cnn_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
cnn_model.add(tf.keras.layers.MaxPooling2D((2, 2)))
# FC
cnn_model.add(tf.keras.layers.Flatten())
cnn_model.add(tf.keras.layers.Dense(128, activation='relu'))
cnn_model.add(tf.keras.layers.BatchNormalization() )
cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))

# 스케줄
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=1e-2,
    decay_steps=10000,
    decay_rate=0.9)
cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# 콜백
early_stopping = tf.keras.callbacks.EarlyStopping( patience=5,restore_best_weights=True)
check_point = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.keras',  save_best_only=True)
# 학습(이미지 제너레이터)
batch_size = 32
hist = cnn_model.fit(train_dataset,epochs=200,batch_size=batch_size,
                     validation_data=valid_dataset,
                               callbacks=[early_stopping,check_point])
```

![image](https://github.com/user-attachments/assets/9b020ab9-e58a-49b5-a49f-aa60439577c6)

```python
# 모델 불러오기
best_cnn_model = tf.keras.models.load_model('/content/best_model.keras')

best_cnn_model.evaluate(test_dataset)
```

```python
# 후버손실  huber loss
  # 회귀에서 사용되는 손실함수 , 평균제곱오차과 평균절대값오차의 장점을 결합한 손실함수
    # 이상치가 있는 데이터에 잘 동작한다.
    # 임계치 보다 작으면 평균제곱차를 사용하고 그렇지 않으면 평균 절대값 오차
```

![image](https://github.com/user-attachments/assets/f6b4b793-a0e5-4f63-921e-c03e73f2d5a4)

```python
def huber_loss(y_true, y_pred):
    error = y_true - y_pred
    is_small_error = tf.abs(error) < 1
    squared_loss = tf.square(error) / 2
    linear_loss = tf.abs(error) - 0.5
    return tf.where(is_small_error, squared_loss, linear_loss) # is_small이면 squared_loss반환하고 그렇지 않으면 linear_loss반환
```

```python
# MNN - 회귀 - 마지막 출력층은 출력이 1
# 데이터는 켈리포니아 데이터셋

import tensorflow as tf
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.california_housing.load_data()

# 모델 생성
model = tf.keras.models.Sequential([
  tf.keras.layers.Input(shape=x_train.shape[1:]),
  tf.keras.layers.Dense(30, activation='relu'),
  tf.keras.layers.Dense(1)
])
# 모델 컴파일
model.compile(loss='mse', optimizer='adam',metrics = ['mae'])
# 학습
model.fit(x_train, y_train, epochs=2, validation_split=0.2)
# 모델 저장
model.save('model.keras')
# 모델 로드
model_loaded = tf.keras.models.load_model('model.keras')
# 평가
model_loaded.evaluate(x_test, y_test)
```

![image](https://github.com/user-attachments/assets/5a6baa6d-1220-4a06-b2a6-0f789e1a8b18)

```python
# 사용자 정의 손실함수

def create_huber(threshold=1.0):
  def huber_fn(y_true, y_pred):
      error = y_true - y_pred
      is_small_error = tf.abs(error) < threshold
      squared_loss = tf.square(error) / 2
      linear_loss  = threshold * tf.abs(error) - threshold ** 2 / 2
      return tf.where(is_small_error, squared_loss, linear_loss)
  return huber_fn
```

```python
# 모델 생성
model = tf.keras.models.Sequential([
  tf.keras.layers.Input(shape=x_train.shape[1:]),
  tf.keras.layers.Dense(30, activation='relu'),
  tf.keras.layers.Dense(1)
])
# 모델 컴파일
model.compile(loss=create_huber(2.0), optimizer='adam',metrics = ['mae'])
# 학습
model.fit(x_train, y_train, epochs=2, validation_split=0.2)
# 모델 저장
model.save('model.keras')
# 모델 로드
model_loaded = tf.keras.models.load_model('model.keras',custom_objects={'huber_fn':create_huber(2.0)})
# 평가
model_loaded.evaluate(x_test, y_test)
```

![image](https://github.com/user-attachments/assets/25ad05b0-8f4a-4d28-8b3b-d8430740c884)

```python
#- 소프트 렐루
def soft_relu(z):
  return tf.math.log(1. + tf.exp(z))

class MyL1Regularizer(tf.keras.regularizers.Regularizer):
  def __init__(self, li=0.01):
    self.li = li
  def __call__(self, weights):
    return tf.reduce_sum(tf.abs(self.li * weights))
  def get_config(self):
    return {'li':self.li}


# 모델 생성
model = tf.keras.models.Sequential([
  tf.keras.layers.Input(shape=x_train.shape[1:]),
  tf.keras.layers.Dense(30, activation=soft_relu,
                        kernel_regularizer=MyL1Regularizer()
                        ),
  tf.keras.layers.Dense(1)
])
# 모델 컴파일
model.compile(loss=create_huber(2.0), optimizer='adam',metrics = ['mae'])
# 학습
model.fit(x_train, y_train, epochs=2, validation_split=0.2)
# 모델 저장
model.save('model.keras')
# 모델 로드
model_loaded = tf.keras.models.load_model('model.keras',
                                          custom_objects={'huber_fn':create_huber(2.0),
                                                          'soft_relu':soft_relu,
                                                          'MyL1Regularizer':MyL1Regularizer()
                                          })
# 평가
model_loaded.evaluate(x_test, y_test)
# 평가 결과과 NAN이 나오는 이유

```

```python
# cnn
# 데이터 전처리
# cnn으로 이미지분류
# 전이학습 모델 vgg 분류
import matplotlib.pyplot as plt
import numpy as np
import torch
from torchvision.datasets import CIFAR10
from torchvision.transforms import ToTensor
from torchvision.utils import make_grid

# 데이터셋 로드
train_dataset = CIFAR10(root='./data', train=True, download=True, transform=ToTensor())
test_dataset = CIFAR10(root='./data', train=False, download=True, transform=ToTensor())
```

```python
# 파이토치의 이미지 데이터는 채널 정보가 앞에 있음 (3,32,32)
for i in range(9):
  plt.subplot(3, 3, i+1)
  plt.imshow(train_dataset[i][0].permute(1, 2, 0)) # imshow는 채널 정보가 마지막에 와야한다.
plt.show()
```

![image](https://github.com/user-attachments/assets/0c9aca02-b007-4296-8ec8-396c3fe50d32)

```python
# 데이터 전처리
from torchvision.transforms import ToTensor, Normalize, Compose, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, RandomCrop
import torchvision.transforms as T

transform = Compose([
    T.ToPILImage(),
    RandomCrop(32, padding=4),
    RandomHorizontalFlip()
])
train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)
test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)

for i in range(9):
  plt.subplot(3, 3, i+1)
  plt.imshow(transform(train_set.data[i]))
  # plt.imshow(train_set[i][0].permute(1, 2, 0)) # imshow는 채널 정보가 마지막에 와야한다.
plt.show()
```

![image](https://github.com/user-attachments/assets/146b548a-ff94-4264-93a0-d71a69a2e45d)

```python
# 이미지 정규화 각 채널 정보를 평균과 표준 편차를 구해서 전처리 부분에 적용
transform = Compose([
    T.ToPILImage(),
    RandomCrop(32, padding=4),
    RandomHorizontalFlip(),
    ToTensor(),
    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    T.ToPILImage()
])

for i in range(9):
  plt.subplot(3, 3, i+1)
  plt.imshow(transform(train_set.data[i]))
  # plt.imshow(train_set[i][0].permute(1, 2, 0)) # imshow는 채널 정보가 마지막에 와야한다.
plt.show()
```


![image](https://github.com/user-attachments/assets/e941590d-8113-4a53-8f3c-215945ba389e)
