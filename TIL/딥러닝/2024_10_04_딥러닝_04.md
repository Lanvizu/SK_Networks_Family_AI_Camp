```python
# 전이학습 - vgg16
import torch
import torch.nn as nn
from torchvision.models import vgg16

# gpu 사용 가능 여부
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# 전이학습 모델 로드
model = vgg16(pretrained=True).to(device) # 기존 가중치를 사용하고 출력만 원하는 형태로 변경
model
```

![image](https://github.com/user-attachments/assets/8890d7ba-5596-4a2f-8985-165cc5f7ab24)

```python
fc = nn.Sequential(
    nn.Linear(in_features=25088, out_features=4096, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=4096, out_features=4096, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=4096, out_features=10, bias=True)
    )
model.classifier = fc
model
```

```python
from torchvision.datasets.cifar import CIFAR10
from torchvision.transforms import ToTensor, Normalize, Compose, Resize, RandomCrop, RandomHorizontalFlip
from torch.utils.data import DataLoader

transforms = Compose([
    Resize((224,224)),
    RandomHorizontalFlip(),
    RandomCrop((224,224),padding=4),
    ToTensor(),
    Normalize((0.5,0.5,0.5),(0.25,0.25,0.25)) # RGB에서 각각에 대한 평균과 표준편차를 이용해서 픽셀의 값을 정규화
])

# 데이터 로더 정의
training_data = CIFAR10(root='./data', train=True, download=True, transform=transforms)
test_data = CIFAR10(root='./data', train=False, download=True, transform=transforms)

train_loader = DataLoader(training_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)
```

## 학습 과정

1. **학습률 설정**
   - 학습률은 모델의 가중치를 업데이트할 때 사용하는 스텝 크기를 결정.

2. **최적화 옵티마이저 선택**
   - 옵티마이저는 손실 함수를 최소화하기 위해 가중치를 업데이트하는 방법을 결정. 일반적으로 사용되는 옵티마이저에는 SGD, Adam, RMSProp 등

3. **에포크만큼 순환**
   - 전체 데이터셋에 대해 한 번 학습을 완료하는 것을 에포크라고 하며, 여러 번 반복하여 모델을 최적화.

   1. **데이터 로드 만큼 순환**
      - 각 에포크에서 데이터 배치를 순차적으로 로드하고 처리.

      2. **기울기 초기화**
         - 이전 배치의 기울기를 초기화하여 새로운 배치의 기울기를 계산할 준비.

      3. **모델을 통해 예측 수행**
         - 입력 데이터를 모델에 통과시켜 예측값을 생성.

      4. **손실 함수 정의 및 오차 계산**
         - 예측값과 실제값 사이의 차이를 손실 함수를 통해 계산.

      5. **역전파 (Backpropagation)**
         - 손실 함수를 통해 계산된 오차를 기반으로 기울기를 계산하고, 역방향으로 전파하여 가중치 업데이트를 준비.

      6. **가중치 업데이트**
         - 옵티마이저를 사용하여 계산된 기울기를 기반으로 가중치를 업데이트.

      7. **오차 모니터링 (선택사항)**
         - 필요에 따라 각 단계별로 오차를 출력하여 학습 상태를 모니터링.

4. **모델 저장 및 불러오기**
   - 학습이 완료된 모델을 저장하여 나중에 재사용 가능. 저장된 모델은 필요시 불러와서 평가 가능.

-----

```python
# 모델을 사용하려면 device에 올려놓는다
model = model.to(device)
lr = 0.001
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
loss_fn = nn.CrossEntropyLoss() # 오차함수 정의
# 학습 루프
from tqdm import tqdm

for epoch in range(5):
    iterator = tqdm(train_loader)
    for data, label in iterator:
        data = data.to(device)
        label = label.to(device)
        optimizer.zero_grad() # 기울기 초기화

        output = model(data) # 예측
        loss = loss_fn(output, label) # 오차 계산
        loss.backward() # 기울기 계산
        optimizer.step() # 가중치 업데이트

        iterator.set_description(f'epoch:{epoch+1} loss:{loss.item()}')
# 모델 저장
torch.save(model.state_dict(), '/content/drive/MyDrive/CIFAR_pretrained.pth')
```

```python
# 모델 불러오기
model.load_state_dict(torch.load('CIFAR_pretrained.pth'))
num_corr = 0
with torch.no_grad():
    for data, label in test_loader:
        data = data.to(device)
        label = label.to(device)
        output = model(data)

```
```python
# ResNet 기본 블럭
import torch
import torch.nn as nn
class BasciBlock(nn.Module):
  def __init__(self, in_channels, out_channels, kernel_size=3):
    super(BasciBlock,self).__init__()
    # 합성곱 층 정의
    self.conv1 = nn.Conv2d(in_channels, out_channels,kernel_size=kernel_size,padding=1)
    self.conv2 = nn.Conv2d(out_channels, out_channels,kernel_size=kernel_size,padding=1)
    self.downsample = nn.Conv2d(in_channels,out_channels,kernel_size=1)
    # 배치정규화
    self.bn1 = nn.BatchNorm2d(out_channels)
    self.bn2 = nn.BatchNorm2d(out_channels)
    # 활성화 함수
    self.relu = nn.ReLU()
  def forward(self,x):
    x_ = x
    x = self.conv1(x)
    x = self.bn1(x)
    x = self.relu(x)
    x = self.conv2(x)
    x = self.bn2(x)
    x_ = self.downsample(x_)
    x += x_
    x = self.relu(x)
    return x
```
```python
class ResNet(nn.Module):
  def __init__(self, num_class = 10):
    super(ResNet,self).__init__()
    # 기본블럭
    self.b1 = BasciBlock(in_channels=3, out_channels=64)
    self.b2 = BasciBlock(in_channels=64, out_channels=128)
    self.b3 = BasciBlock(in_channels=128, out_channels=16)
    # 폴링
    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)
    # 분류기 FC
    self.fc1 = nn.Linear(in_features=28*28*16, out_features=2048)
    self.fc2 = nn.Linear(in_features=2048, out_features=512)
    self.fc3 = nn.Linear(in_features=512, out_features=num_class)
    # 활성화 함수
    self.relu = nn.ReLU()
  def forward(self,x):
    x = self.pool( self.b1(x) )
    x = self.pool( self.b2(x) )
    x = self.pool( self.b3(x) )
    # 분류기
    x = torch.flatten(x, start_dim=1)  # 시작차수  (배치사이즈, 채널,가로,세로)
    x = self.relu(self.fc1(x))
    x = self.relu(self.fc2(x))
    x = self.fc3(x)
    return x
```

```python
# # 에러 핸들링
# temp = BasciBlock(in_channels=3, out_channels=64)
# for data, label in train_loader:
#   temp(data)
#   break

# 학습
lr = 1e-4
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
for epoch in range(1):
  iterator = tqdm(train_loader)
  for data,label in iterator:
    data = data.to(device); label = label.to(device)
    optimizer.zero_grad()
    output = model(data)
    loss = loss_fn(output, label)
    loss.backward()
    optimizer.step()
    iterator.set_description(f"epoch:{epoch+1} loss:{loss.item()}")
torch.save(model.state_dict(), "/content/drive/MyDrive/model/ResNet.pth")
```
```python
# ResNet 전이 학습
import torch
import torch.nn as nn
from torchvision.models.resnet import resnet50

# 전이학습 VGG16 이용해서 Resnet50 전이학습 파인튜닝으로
device = 'cuda' if torch.cuda.is_available() else 'cpu'
resnet = resnet50(weights=True).to(device)
resnet
```

```python
# 파인튜닝을 위해서는 가중치를 고정
for param in resnet.parameters():
  param.requires_grad = False

# 모델의 분류기를 10개를 분류하는 FC로 변경
resnet.fc = nn.Linear(in_features=2048, out_features=10, bias=True)
resnet
```

```python
# 데이터준비..
# transform을 이용해서 입력데이터의 크기를 고정시킨다.. 224
from torchvision.datasets.cifar import CIFAR10
from torchvision.transforms import Compose, ToTensor,Resize, RandomHorizontalFlip,RandomCrop, Normalize
from torch.utils.data import DataLoader
transforms = Compose([
    Resize((224,224)),
    RandomHorizontalFlip(),
    RandomCrop((224,224),padding=4),
    ToTensor(),
    Normalize((0.5,0.5,0.5),(0.25,0.25,0.25))  # RGB에서 각각에대한 평균관 표준편차를 이용해서 픽셀의 값을 정규화
])
training_data = CIFAR10(    root='./data',    train=True,    download=True,    transform=transforms)
test_data = CIFAR10(    root='./data',    train=False,    download=True,    transform=transforms)
train_loader = DataLoader(training_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)
```
```python
from tqdm import tqdm
# 학습
lr = 1e-4
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet.parameters(), lr=lr)
for epoch in range(1):
  iterator = tqdm(train_loader)
  for data,label in iterator:
    data = data.to(device); label = label.to(device)
    optimizer.zero_grad()
    output = resnet(data)
    loss = loss_fn(output, label)
    loss.backward()
    optimizer.step()
    iterator.set_description(f"epoch:{epoch+1} loss:{loss.item()}")
torch.save(resnet.state_dict(), "/content/drive/MyDrive/model/ResNet50.pth")
```

-----

```python
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
# 시각화 셋팅
plt.rc('font',size=4)
plt.rc('axes',labelsize=4, titlesize=14)
plt.rc('legend',fontsize=14)
plt.rc('xtick',labelsize=14); plt.rc('ytick',labelsize=14)

from sklearn.datasets import load_sample_images
images = load_sample_images()['images']
np.array(images).shape
# (2, 427, 640, 3)

plt.imshow(images[0])
```

![image](https://github.com/user-attachments/assets/9cbc82d5-ede4-4e5c-9870-76f38632ffe7)


```python
images = load_sample_images()['images']
images = tf.keras.layers.CenterCrop(height=70, width=120)(images)
images = tf.keras.layers.Rescaling(scale=1/255)(images)
print(images.shape)
# (2, 70, 120, 3)
plt.imshow(images[0])
```

![image](https://github.com/user-attachments/assets/c9f9f13b-0f11-4f4e-a8e0-15ca8b6d772a)

```python
tf.random.set_seed(42)
# (2, 70, 120, 3)
# 스트라이드 1 패딩은 없고... kernel_size-1 한 값으로 shape를 빼준다.
conv_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=7)
fmaps = conv_layer(images)
fmaps.shape
# TensorShape([2, 64, 114, 32])
```

```python
# 채널을이용해서 채널개수를 늘려주면... conv학습할때 다양한 패턴을 학습
plt.figure(figsize=(12,8))
for i in range(4):
  plt.subplot(2,2,i+1)
  plt.imshow(fmaps[i//2,:,:,i//2],cmap='gray_r')
  plt.axis('off')
plt.show()
```

![image](https://github.com/user-attachments/assets/b244e2b5-c6c4-419c-8d49-e6a10bb17939)

```python
# 패팅... 제로패팅  스트라이드가 1이면.... 크기는 변동 없다.
conv_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=7,padding='same')   # 제로패딩 추가
fmaps = conv_layer(images)
fmaps.shape
# TensorShape([2, 70, 120, 32])
```

```python
# padding='same' 이면 strides으로 나눈다. 나눠지지 않으면 나머지가 0이되도록 연산
conv_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=7,padding='same',strides=2)   # 제로패딩 추가
fmaps = conv_layer(images)
fmaps.shape
# TensorShape([2, 35, 60, 32])
```

```python
# 패딩이 valid 여부에 따라서 shape 형태가 달라진다.
def conv_output_size(input_size, kernel_size, stride=1, padding ='valid'):
  if padding == 'valid':
    z = input_size - kernel_size + 1
    output_size = z // stride
    num_ignored = z % stride
    return output_size, num_ignored
  else:
    output_size =  (input_size -1) // stride + 1
    num_padded = (output_size - 1) * stride + kernel_size - input_size
    return output_size, num_padded
conv_output_size(np.array([70,120]),kernel_size=7, stride=2,padding='same'        )

# (array([35, 60]), array([5, 5]))
```

```python
# 가중치 7, 7, 3, 32 --> 7, 7 필터의 크기, 3 입력데이터의 채널수 , 32 필터의 개수
kernels, bias = conv_layer.weights
kernels, bias
```

![image](https://github.com/user-attachments/assets/56fafda2-ba0b-4169-9a09-6eb5130db859)

```python
# 폴링 - 케라스로 구현
max_pool = tf.keras.layers.AveragePooling2D(pool_size=2, strides=2)
output = max_pool(images)
print(images.shape)
# (2, 70, 120, 3)
```
```python
import matplotlib as mpl
fig = plt.figure(figsize=(12,8))
gs = mpl.gridspec.GridSpec(1,2,width_ratios=(2,1))
fig.add_subplot(gs[0,0])
plt.imshow(images[0])
fig.add_subplot(gs[0,1])
plt.imshow(output[0])
```

![image](https://github.com/user-attachments/assets/6b7e7f41-416d-424c-9140-f66aa1a0cbeb)


```python
plt.imshow(output[0])
```

![image](https://github.com/user-attachments/assets/6dc935fd-a7e5-4187-b4b4-d988ed1ac72f)

```python
# CNN
# mnist 분류기
(x_train_f,y_train_f),(x_test,y_test) = tf.keras.datasets.mnist.load_data()
# 채널정보를 추가하고 그리고 정규화
x_train_f = np.expand_dims(x_train_f,axis=-1) / 255.
x_test = np.expand_dims(x_test,axis=-1) / 255.
from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(x_train_f,y_train_f,test_size=0.1)
x_train.shape
# (54000, 28, 28, 1)
```

```python
# 재현성 보장 : 랜덤시드를 고정시켜서 데이터의 변화에따른 성능변화를 금지시켜서 오로지 모델선택에 관해 일관성을 유지하는 방법
tf.random.set_seed(42)

from functools import partial
DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding='same', activation='relu')
model = tf.keras.Sequential([
    DefaultConv2D(filters=64, kernel_size=7, input_shape=x_train.shape[1:]), # [28,28,1]
    tf.keras.layers.MaxPooling2D(pool_size=2),
    DefaultConv2D(filters=128),
    DefaultConv2D(filters=128),
    tf.keras.layers.MaxPool2D(),
    DefaultConv2D(filters=256),
    DefaultConv2D(filters=256),
    tf.keras.layers.MaxPool2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(units=128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(units=10, activation='softmax')
])
```

```python
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))
scores = model.evaluate(x_test, y_test)
# 예측
x_new = x_test[:10]
y_pred = model.predict(x_new)
```

```python
DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding="same",strides=1,use_bias=False)

class ResidualBlock(tf.keras.layers.Layer):
  def __init__(self,filters,strides=1,activation='relu', **kwargs) -> None:
    super().__init__(**kwargs)
    self.activation = tf.keras.activations.get(activation)
    self.main_layers = [
        DefaultConv2D(filters,strides=strides),
        tf.keras.layers.BatchNormalization(),
        self.activation,
        DefaultConv2D(filters),
        tf.keras.layers.BatchNormalization()
    ]
    # residualblock skip connection
    self.skip_layers = []
    # 스트라이드가 1보다 크면 입력과 출력의 차원이 다르므로 스킵커넥션에서 맞춰주기 위해서 1x1합성곱과 배치정규화를 추가
    if strides > 1:
      self.skip_layers = [
          DefaultConv2D(filters,kernel_size=1,strides=strides),
          tf.keras.layers.BatchNormalization()
      ]
  def call(self, inputs):
    z = inputs  # 입력을 z에 저장
    for layer in self.main_layers:  # conv batch 차례대로 통과
      z = layer(z)
    skip_z = inputs  # skip_z 원본 입력을 저장
    for layer in self.skip_layers: # 스킵레이어를 통과시켜서 크기를 맞춰준다
      skip_z = layer(skip_z)
    return self.activation(z + skip_z)

```

```python
# ResNet(residual network)
model = tf.keras.Sequential([
    DefaultConv2D(64,kernel_size=7,strides=2,input_shape=[224,224,3]), # 다운샘플링
    tf.keras.layers.BatchNormalization(), # 속도향상 불안정한 학습을 방지
    tf.keras.layers.Activation('relu'),
    tf.keras.layers.MaxPool2D(pool_size=3,strides=2,padding='same')
])
# Residual Block 추가
# 64 필터의 블럭을 3
# 128 필터의 블럭을 4
# 256 필터의 블럭을 6
# 512 필터의 블럭을 3
prev_filters = 64
for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:
  strides = 1 if filters == prev_filters else 2
  model.add(ResidualBlock(filters,strides=strides))
  prev_filters = filters
# 컨볼류션의 완성
# 분류기 FC
model.add(tf.keras.layers.GlobalAvgPool2D())
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(10,activation='softmax'))
```
