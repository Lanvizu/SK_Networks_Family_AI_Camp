```python
import tensorflow as tf

encoder = tf.keras.Sequential([tf.keras.layers.Dense(2)])
decoder = tf.keras.Sequential([tf.keras.layers.Dense(3)])
autoencoder = tf.keras.Sequential([encoder, decoder])

optimizer = tf.keras.optimizers.Adam(learning_rate=0.5)
autoencoder.compile(optimizer=optimizer, loss='mse')

import numpy as np
from scipy.spatial.transform import Rotation

m = 60
X = np.zeros((m, 3))  # 3D 데이터 세트 초기화
np.random.seed(42)
angles = (np.random.rand(m) ** 3 + 0.5) * 2 * np.pi  # 고르지 않은 분포
X[:, 0], X[:, 1] = np.cos(angles), np.sin(angles) * 0.5  # 타원형
X += 0.28 * np.random.randn(m, 3)  # 노이즈 추가
X = Rotation.from_rotvec([np.pi / 29, -np.pi / 20, np.pi / 4]).apply(X)
X_train = X + [0.2, 0, 0.2]  # 약간 이동
```

```python
X.shape
# (60, 3)

history = autoencoder.fit(X_train, X_train, epochs=500, verbose=False)
codings = encoder.predict(X_train)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(5, 5))
ax = fig.add_subplot(111, projection='3d')
# x 원본 데이터
ax.scatter(X[:, 0], X[:, 1], X[:, 2], c='blue', label='Original Data')

# 이동한 데이터
ax.scatter(X_train[:, 0], X_train[:, 1], X_train[:, 2], c='red', label='Moved Data')

ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.legend()
plt.show()
```

![image](https://github.com/user-attachments/assets/f478655e-38a8-473e-a28d-ebbba9364d5e)

## 적층 오토인코더 (Stacked Autoencoder)

- 오토인코더의 변형으로, 여러 층을 쌓아 더 복잡한 패턴을 학습할 수 있는 구조
- 여러 개의 오토인코더를 층으로 쌓은 형태
- 각 층은 이전 층의 출력 값을 입력으로 받아 학습

### 특징

- 각 층을 독립적으로 미리 학습한 후, 전체 네트워크를 fine-tuning
- **장점**: 각 층의 독립적 학습으로 초기 가중치 설정에 도움
- **단점**: 층별 독립 학습으로 전체 최적화에 비해 효율성이 떨어질 수 있음

### 학습 과정

1. 첫 번째 은닉층 학습
2. 첫 번째 은닉층의 출력을 이용해 두 번째 은닉층 학습
3. 이 과정을 모든 층에 대해 반복
4. 전체 네트워크를 fine-tuning

## 심층 오토인코더 (Deep Autoencoder)

- 여러 개의 은닉층을 가진 오토인코더
- 적층 구조와 유사하나, 전체 모델을 동시에 학습

### 특징

- **장점**: 
  - 비선형성을 더 잘 표현
  - 더 복잡한 특징 추출 가능
- **단점**: 
  - 기울기 소실 문제 발생 가능
  - 과적합 위험 증가

### 해결 방법

- 활성화 함수 선택 (ReLU 등)
- 배치 정규화
- 잔차 연결 (Residual connections)
- 적절한 초기화 방법 사용

-----

```python
# 적층 오토 인코더 구현 - fashion mnist
(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()
x_train_full / 255.0 ; x_test / 255.0

from sklearn.model_selection import train_test_split
x_train, x_vaild, y_train, y_vaild = train_test_split(x_train_full, y_train_full, stratify=y_train_full,test_size=0.2, random_state = 42)

x_train_full.shape
# (60000, 28, 28)
```

```python
# 케라스로 적층 오토인코더 구현
# 일반적인 심층 MLP와 매우 비슷하게 적층 오토인코더를 구현
stacked_encoder = tf.keras.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dense(30, activation='relu'),
])
stacked_decoder = tf.keras.Sequential([
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dense(28*28),
    tf.keras.layers.Reshape([28, 28])
])
stacked_autoencoder = tf.keras.Sequential([stacked_encoder, stacked_decoder])

stacked_autoencoder.compile(optimizer='nadam', loss='mse')
history = stacked_autoencoder.fit(x_train, x_train, epochs=20,
                                  validation_data = (x_vaild, x_vaild))
```

```python
# 재구성 시각화
import numpy as ap
def plot_reconstructions(model, images = x_vaild, n_images=5):
  reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)
  fig = plt.figure(figsize = (n_images * 1.5, 3))
  for image_index in range(n_images):
    plt.subplot(2, n_images, 1+ image_index)
    plt.imshow(images[image_index], cmap = "binary")
    plt.axis("off")
    plt.subplot(2, n_images, 1 + n_images + image_index)
    plt.imshow(reconstructions[image_index], cmap="binary")
    plt.axis("off")

plot_reconstructions(stacked_autoencoder)
plt.show()
```

![image](https://github.com/user-attachments/assets/1f52098b-a915-4478-bfa0-c3f9d7fac2bb)

```python
from sklearn.manifold import TSNE
x_valid_compressed = stacked_encoder.predict(x_vaild)
tsne = TSNE(init = "pca", learning_rate="auto", random_state=42)
x_vaild_2D = tsne.fit_transform(x_valid_compressed)

plt.scatter(x_vaild_2D[:, 0], x_vaild_2D[:, 1], c=y_vaild, s=10, cmap="tab10")
plt.show()
```

![image](https://github.com/user-attachments/assets/a849a68e-61a9-43fe-adaa-261ba4bff9f5)

-----

## 가중치 묶기 (Weight Tying)

- 인코더의 가중치 전치를 디코더의 가중치로 사용하여 두 부분의 가중치를 묶는 기법

### 원리

- 인코더가 가중치 W를 사용하면, 디코더는 W의 전치(W^T)를 사용
- 추가적인 가중치 매개변수가 필요 없음

### 장점

- 학습 파라미터 수가 절반으로 감소
- 모델의 복잡도 감소
- 과적합 위험 감소
- 인코더와 디코더 간 일관성 유지로 대칭적 구조 형성
- 안정적인 학습 가능

### 학습 특성

- 가중치 공유로 인해 역전파 시 한 번의 업데이트로 인코더와 디코더 동시 갱신

### 적용 분야

- 오토인코더
- 순환 신경망 (RNN)
- 언어 모델


```python
import tensorflow as tf

class DenseTranspose(tf.keras.layers.Layer):
    def __init__(self, dense, activation=None, **kwargs):
        super().__init__(**kwargs)
        self.dense = dense
        self.activation = tf.keras.activations.get(activation)

    def build(self, batch_input_shape):
      #  dense 레이어의 weight를 통해 입력 개수를 추출합니다.
        input_dim = self.dense.weights[0].shape[0]  # weights[0]는 입력 가중치 행렬입니다.
        self.biases = self.add_weight(name="bias",
                                      shape=[input_dim],
                                      initializer="zeros")
        super().build(batch_input_shape)

    def call(self, inputs):
        Z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)
        return self.activation(Z + self.biases)
```
```python
tf.random.set_seed(42)  # 추가 코드 - CPU에서 재현성 보장

dense_1 = tf.keras.layers.Dense(100, activation="relu")
dense_2 = tf.keras.layers.Dense(30, activation="relu")

tied_encoder = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape = x_train.shape[1:]),
    dense_1,
    dense_2
])

tied_decoder = tf.keras.Sequential([
    DenseTranspose(dense_2, activation="relu"),
    DenseTranspose(dense_1),
    tf.keras.layers.Reshape([28, 28])
])

tied_ae = tf.keras.Sequential([tied_encoder, tied_decoder])

# 추가 코드 - 모델을 컴파일하고 훈련합니다.
tied_ae.compile(loss="mse", optimizer="nadam")
history = tied_ae.fit(x_train, x_train, epochs=10,
                      validation_data=(x_vaild, x_vaild))
```

```python
import matplotlib.pyplot as plt
y_pred = tied_ae.predict(x_test[[100]])
plt.subplot(1,2,1)
plt.imshow(x_test[100],cmap='gray_r')
plt.subplot(1,2,2)
plt.imshow(y_pred[0],cmap='gray_r')
plt.show()
```

![image](https://github.com/user-attachments/assets/04b7c5d3-46ab-490b-8333-e389243a8489)

-----

```python
# 데이터
import tensorflow as tf
(x_train_full,y_train_full),(x_test,y_test) =  tf.keras.datasets.fashion_mnist.load_data()
x_train_full / 255.0 ; x_test / 255.0
from sklearn.model_selection import train_test_split
x_train,x_valid,y_train,y_valid \
= train_test_split(x_train_full,y_train_full,stratify=y_train_full, test_size=0.2,random_state=42)
```
```python
# units : 인코더의 출력
# x_train : 오토인코더는 입력 과 출력이 동일
# output_activation 디코더의 출력 활성화 함수
# 데이터의 차원축소, 노이즈 제거, 특징 학습 용도로 다양하게 사용
def train_autoencoder(units, x_train, x_valid, epochs=20, output_activation=None):
  n_inputs = x_train.shape[-1]  # 28*28
  encoder = tf.keras.layers.Dense(units,activation='relu')
  decoder = tf.keras.layers.Dense(n_inputs,activation=output_activation)
  autoencoder = tf.keras.Sequential([encoder,decoder])
  autoencoder.compile(loss='mse',optimizer='nadam')
  autoencoder.fit(x_train,x_train,epochs=epochs,validation_data=(x_valid,x_valid))
  return encoder,decoder,encoder(x_train), encoder(x_valid)
```
```python
x_train_flat = tf.keras.layers.Flatten()(x_train)
x_valid_flat = tf.keras.layers.Flatten()(x_valid)
dnc1,dec1,x_train_enc1, x_valid_enc1 =  train_autoencoder(100,x_train_flat,x_valid_flat)
dnc2,dec2,x_train_enc2, x_valid_enc2 =  train_autoencoder(30,x_train_enc1,x_valid_enc1)
```

```python
stacked_1_by_1 = tf.keras.Sequential([
    tf.keras.layers.Flatten(),
    dnc1,dnc2,dec2,dec1,
    tf.keras.layers.Reshape((28,28))
    ])

stacked_1_by_1.save('/content/stacked_1_by_1.keras')

stacked_1_by_1 = tf.keras.models.load_model('/content/stacked_1_by_1.keras')
import matplotlib.pyplot as plt
y_pred = stacked_1_by_1.predict(x_test[[100]])
plt.subplot(1,2,1)
plt.imshow(x_test[100],cmap='gray_r')
plt.subplot(1,2,2)
plt.imshow(y_pred[0],cmap='gray_r')
plt.show()
```

![image](https://github.com/user-attachments/assets/fa4b2d91-633c-44af-b93b-8a0e08c9f2a4)


-----
```python
# 데이터
import tensorflow as tf
from sklearn.model_selection import train_test_split
(x,y),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()
x_train,x_val,y_train,y_val = train_test_split(x,y, stratify=y  ,test_size=0.2,random_state=42)

```
```python
# 입력에 사용된 데이터는 28 28 --> 28 28 1
# conv 3차원
# fc(dense) 1차원
# cp cp cp cp
conv_enc = tf.keras.Sequential([
    tf.keras.layers.Reshape((28,28,1)),

    tf.keras.layers.Conv2D(16,3,padding='same',activation='relu'),
    tf.keras.layers.MaxPool2D(),  # 14 14 16

    tf.keras.layers.Conv2D(32,3,padding='same',activation='relu'),
    tf.keras.layers.MaxPool2D(), # 7 7 32

    tf.keras.layers.Conv2D(64,3,padding='same',activation='relu'),
    tf.keras.layers.MaxPool2D(), # 3 3 64

    tf.keras.layers.Conv2D(30,3,padding='same',activation='relu'),
    tf.keras.layers.GlobalMaxPool2D() # 1 1 30
])
conv_dec = tf.keras.Sequential([
    tf.keras.layers.Dense(3*3*64,activation='relu'),
    tf.keras.layers.Reshape((3,3,64)),
    tf.keras.layers.Conv2DTranspose(32,3,strides=2,activation='relu'),
    tf.keras.layers.Conv2DTranspose(16,3,strides=2,padding='same', activation='relu'),
    # 마지막 출력을 2차원
    tf.keras.layers.Conv2DTranspose(1,3,strides=2,padding='same'),
    tf.keras.layers.Reshape((28,28))
])
conv_ae = tf.keras.Sequential([conv_enc,conv_dec])
conv_ae.compile(loss='mse',optimizer='nadam')
history = conv_ae.fit(x_train,x_train,epochs=1,validation_data=(x_val,x_val))
conv_ae.save('/content/conv_ae.keras')
```

```python
import tensorflow as tf
import matplotlib.pyplot as plt
conv_ae = tf.keras.models.load_model('/content/conv_ae.keras')
import matplotlib.pyplot as plt
plt.figure(figsize=(2,2))
y_pred = conv_ae.predict(x_test[[100]])
plt.subplot(1,2,1)
plt.imshow(x_test[100],cmap='gray_r')
plt.subplot(1,2,2)
plt.imshow(y_pred[0],cmap='gray_r')
plt.show()
```

![image](https://github.com/user-attachments/assets/809dd216-f207-4e01-9d9c-b839bbcfcfa7)

