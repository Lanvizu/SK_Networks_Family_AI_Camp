{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/yoeun/Downloads/study/E Commerce Dataset.xlsx', sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PreferredLoginDevice</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>WarehouseToHome</th>\n",
       "      <th>PreferredPaymentMode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourSpendOnApp</th>\n",
       "      <th>NumberOfDeviceRegistered</th>\n",
       "      <th>PreferedOrderCat</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfAddress</th>\n",
       "      <th>Complain</th>\n",
       "      <th>OrderAmountHikeFromlastYear</th>\n",
       "      <th>CouponUsed</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>DaySinceLastOrder</th>\n",
       "      <th>CashbackAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50001</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mobile Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laptop &amp; Accessory</td>\n",
       "      <td>2</td>\n",
       "      <td>Single</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Laptop &amp; Accessory</td>\n",
       "      <td>5</td>\n",
       "      <td>Single</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>CC</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>5</td>\n",
       "      <td>Single</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Churn  Tenure PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
       "0       50001      1     4.0         Mobile Phone         3              6.0   \n",
       "1       50002      1     NaN                Phone         1              8.0   \n",
       "2       50003      1     NaN                Phone         1             30.0   \n",
       "3       50004      1     0.0                Phone         3             15.0   \n",
       "4       50005      1     0.0                Phone         1             12.0   \n",
       "\n",
       "  PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  \\\n",
       "0           Debit Card  Female             3.0                         3   \n",
       "1                  UPI    Male             3.0                         4   \n",
       "2           Debit Card    Male             2.0                         4   \n",
       "3           Debit Card    Male             2.0                         4   \n",
       "4                   CC    Male             NaN                         3   \n",
       "\n",
       "     PreferedOrderCat  SatisfactionScore MaritalStatus  NumberOfAddress  \\\n",
       "0  Laptop & Accessory                  2        Single                9   \n",
       "1              Mobile                  3        Single                7   \n",
       "2              Mobile                  3        Single                6   \n",
       "3  Laptop & Accessory                  5        Single                8   \n",
       "4              Mobile                  5        Single                3   \n",
       "\n",
       "   Complain  OrderAmountHikeFromlastYear  CouponUsed  OrderCount  \\\n",
       "0         1                         11.0         1.0         1.0   \n",
       "1         1                         15.0         0.0         1.0   \n",
       "2         1                         14.0         0.0         1.0   \n",
       "3         0                         23.0         0.0         1.0   \n",
       "4         0                         11.0         1.0         1.0   \n",
       "\n",
       "   DaySinceLastOrder  CashbackAmount  \n",
       "0                5.0          159.93  \n",
       "1                0.0          120.90  \n",
       "2                3.0          120.28  \n",
       "3                3.0          134.07  \n",
       "4                3.0          129.60  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5630 entries, 0 to 5629\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   CustomerID                   5630 non-null   int64  \n",
      " 1   Churn                        5630 non-null   int64  \n",
      " 2   Tenure                       5366 non-null   float64\n",
      " 3   PreferredLoginDevice         5630 non-null   object \n",
      " 4   CityTier                     5630 non-null   int64  \n",
      " 5   WarehouseToHome              5379 non-null   float64\n",
      " 6   PreferredPaymentMode         5630 non-null   object \n",
      " 7   Gender                       5630 non-null   object \n",
      " 8   HourSpendOnApp               5375 non-null   float64\n",
      " 9   NumberOfDeviceRegistered     5630 non-null   int64  \n",
      " 10  PreferedOrderCat             5630 non-null   object \n",
      " 11  SatisfactionScore            5630 non-null   int64  \n",
      " 12  MaritalStatus                5630 non-null   object \n",
      " 13  NumberOfAddress              5630 non-null   int64  \n",
      " 14  Complain                     5630 non-null   int64  \n",
      " 15  OrderAmountHikeFromlastYear  5365 non-null   float64\n",
      " 16  CouponUsed                   5374 non-null   float64\n",
      " 17  OrderCount                   5372 non-null   float64\n",
      " 18  DaySinceLastOrder            5323 non-null   float64\n",
      " 19  CashbackAmount               5630 non-null   float64\n",
      "dtypes: float64(8), int64(7), object(5)\n",
      "memory usage: 879.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/g1njf16x0rz622dj3vfvfyy80000gn/T/ipykernel_40844/4143997425.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Tenure'].fillna(np.random.randint(61,72), inplace=True)\n",
      "/var/folders/b1/g1njf16x0rz622dj3vfvfyy80000gn/T/ipykernel_40844/4143997425.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['WarehouseToHome'].fillna(0, inplace=True)\n",
      "/var/folders/b1/g1njf16x0rz622dj3vfvfyy80000gn/T/ipykernel_40844/4143997425.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CouponUsed'].fillna(0, inplace=True)\n",
      "/var/folders/b1/g1njf16x0rz622dj3vfvfyy80000gn/T/ipykernel_40844/4143997425.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['OrderCount'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)  # 시드 고정\n",
    "df['Tenure'].fillna(np.random.randint(61,72), inplace=True)\n",
    "df['WarehouseToHome'].fillna(0, inplace=True)\n",
    "\n",
    "df = df[df['HourSpendOnApp'].notna()]\n",
    "df.drop(columns=['OrderAmountHikeFromlastYear'], inplace=True)\n",
    "df['CouponUsed'].fillna(0, inplace=True)\n",
    "df['OrderCount'].fillna(0, inplace=True)\n",
    "df = df[df['DaySinceLastOrder'].notna()]\n",
    "df = df[~df['DaySinceLastOrder'].isin([31, 46, 30])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5065 entries, 0 to 5629\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CustomerID                5065 non-null   int64  \n",
      " 1   Churn                     5065 non-null   int64  \n",
      " 2   Tenure                    5065 non-null   float64\n",
      " 3   PreferredLoginDevice      5065 non-null   object \n",
      " 4   CityTier                  5065 non-null   int64  \n",
      " 5   WarehouseToHome           5065 non-null   float64\n",
      " 6   PreferredPaymentMode      5065 non-null   object \n",
      " 7   Gender                    5065 non-null   object \n",
      " 8   HourSpendOnApp            5065 non-null   float64\n",
      " 9   NumberOfDeviceRegistered  5065 non-null   int64  \n",
      " 10  PreferedOrderCat          5065 non-null   object \n",
      " 11  SatisfactionScore         5065 non-null   int64  \n",
      " 12  MaritalStatus             5065 non-null   object \n",
      " 13  NumberOfAddress           5065 non-null   int64  \n",
      " 14  Complain                  5065 non-null   int64  \n",
      " 15  CouponUsed                5065 non-null   float64\n",
      " 16  OrderCount                5065 non-null   float64\n",
      " 17  DaySinceLastOrder         5065 non-null   float64\n",
      " 18  CashbackAmount            5065 non-null   float64\n",
      "dtypes: float64(7), int64(7), object(5)\n",
      "memory usage: 791.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# 속성이 object인 데이터들의 집합\n",
    "cat_col = [col for col in df.columns if df[col].dtypes == 'object']\n",
    "\n",
    "# 속성이 object 아닌 데이터들의 집합\n",
    "num_col = [col for col in df.columns if df[col].dtypes != 'object']\n",
    "\n",
    "\n",
    "# 범주형 변수를 숫자로 인코딩 - 추후 predict streamlit 을 위해 하나의 내용으로 변경\n",
    "label_encoders = {\n",
    "    'PreferredLoginDevice': LabelEncoder(),\n",
    "    'PreferredPaymentMode': LabelEncoder(),\n",
    "    'Gender': LabelEncoder(),\n",
    "    'PreferedOrderCat': LabelEncoder(),\n",
    "    'MaritalStatus': LabelEncoder()\n",
    "}\n",
    "\n",
    "for col, encoder in label_encoders.items():\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "# 수치형 변수를 위한 StandardScaler 저장 딕셔너리\n",
    "scalers = {}\n",
    "\n",
    "# 수치형 변수 리스트\n",
    "numeric_columns = ['CityTier', 'WarehouseToHome', 'HourSpendOnApp', \n",
    "                   'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress', 'Complain', \n",
    "                    'CouponUsed', 'OrderCount','DaySinceLastOrder', 'CashbackAmount']  # 예시 수치형 변수\n",
    "\n",
    "# 각 수치형 변수에 대해 StandardScaler 생성 및 적용\n",
    "for col in numeric_columns:\n",
    "    scaler = StandardScaler()\n",
    "    # fit_transform을 사용하여 데이터 스케일링\n",
    "    df[col] = scaler.fit_transform(df[[col]])  # DataFrame 형식으로 전달\n",
    "    # 각 스케일러를 저장\n",
    "    scalers[col] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PreferredLoginDevice</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>WarehouseToHome</th>\n",
       "      <th>PreferredPaymentMode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourSpendOnApp</th>\n",
       "      <th>NumberOfDeviceRegistered</th>\n",
       "      <th>PreferedOrderCat</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfAddress</th>\n",
       "      <th>Complain</th>\n",
       "      <th>CouponUsed</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>DaySinceLastOrder</th>\n",
       "      <th>CashbackAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50001</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.479106</td>\n",
       "      <td>-0.983967</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113893</td>\n",
       "      <td>-0.678414</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.777578</td>\n",
       "      <td>2</td>\n",
       "      <td>1.840180</td>\n",
       "      <td>1.575910</td>\n",
       "      <td>-0.353570</td>\n",
       "      <td>-0.633891</td>\n",
       "      <td>0.107397</td>\n",
       "      <td>-0.345321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.710481</td>\n",
       "      <td>-0.762603</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113893</td>\n",
       "      <td>0.300830</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.052802</td>\n",
       "      <td>2</td>\n",
       "      <td>1.065794</td>\n",
       "      <td>1.575910</td>\n",
       "      <td>-0.901393</td>\n",
       "      <td>-0.633891</td>\n",
       "      <td>-1.289536</td>\n",
       "      <td>-1.133221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.710481</td>\n",
       "      <td>1.672403</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.269482</td>\n",
       "      <td>0.300830</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.052802</td>\n",
       "      <td>2</td>\n",
       "      <td>0.678601</td>\n",
       "      <td>1.575910</td>\n",
       "      <td>-0.901393</td>\n",
       "      <td>-0.633891</td>\n",
       "      <td>-0.451376</td>\n",
       "      <td>-1.145737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.479106</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.269482</td>\n",
       "      <td>0.300830</td>\n",
       "      <td>2</td>\n",
       "      <td>1.396749</td>\n",
       "      <td>2</td>\n",
       "      <td>1.452987</td>\n",
       "      <td>-0.634554</td>\n",
       "      <td>-0.901393</td>\n",
       "      <td>-0.633891</td>\n",
       "      <td>-0.451376</td>\n",
       "      <td>-0.867358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.710481</td>\n",
       "      <td>0.786946</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113893</td>\n",
       "      <td>1.280074</td>\n",
       "      <td>4</td>\n",
       "      <td>1.396749</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.870172</td>\n",
       "      <td>1.575910</td>\n",
       "      <td>1.289898</td>\n",
       "      <td>1.118270</td>\n",
       "      <td>0.666170</td>\n",
       "      <td>-0.764000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Churn  Tenure  PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
       "0       50001      1     4.0                     1  1.479106        -0.983967   \n",
       "1       50002      1    67.0                     2 -0.710481        -0.762603   \n",
       "2       50003      1    67.0                     2 -0.710481         1.672403   \n",
       "3       50004      1     0.0                     2  1.479106         0.012172   \n",
       "5       50006      1     0.0                     0 -0.710481         0.786946   \n",
       "\n",
       "   PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  \\\n",
       "0                     4       0        0.113893                 -0.678414   \n",
       "1                     6       1        0.113893                  0.300830   \n",
       "2                     4       1       -1.269482                  0.300830   \n",
       "3                     4       1       -1.269482                  0.300830   \n",
       "5                     4       0        0.113893                  1.280074   \n",
       "\n",
       "   PreferedOrderCat  SatisfactionScore  MaritalStatus  NumberOfAddress  \\\n",
       "0                 2          -0.777578              2         1.840180   \n",
       "1                 3          -0.052802              2         1.065794   \n",
       "2                 3          -0.052802              2         0.678601   \n",
       "3                 2           1.396749              2         1.452987   \n",
       "5                 4           1.396749              2        -0.870172   \n",
       "\n",
       "   Complain  CouponUsed  OrderCount  DaySinceLastOrder  CashbackAmount  \n",
       "0  1.575910   -0.353570   -0.633891           0.107397       -0.345321  \n",
       "1  1.575910   -0.901393   -0.633891          -1.289536       -1.133221  \n",
       "2  1.575910   -0.901393   -0.633891          -0.451376       -1.145737  \n",
       "3 -0.634554   -0.901393   -0.633891          -0.451376       -0.867358  \n",
       "5  1.575910    1.289898    1.118270           0.666170       -0.764000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['CustomerID', 'Churn'])\n",
    "y = df['Churn']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame:\n",
      "Churn\n",
      "0    2709\n",
      "1     532\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation DataFrame:\n",
      "Churn\n",
      "0    673\n",
      "1    138\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test DataFrame:\n",
      "Churn\n",
      "0    848\n",
      "1    165\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "print(\"Train DataFrame:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nValidation DataFrame:\")\n",
    "print(y_val.value_counts())\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Logistic------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.93       673\n",
      "           1       0.80      0.31      0.45       138\n",
      "\n",
      "    accuracy                           0.87       811\n",
      "   macro avg       0.84      0.65      0.69       811\n",
      "weighted avg       0.86      0.87      0.84       811\n",
      "\n",
      "-----DecisionTree------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       673\n",
      "           1       0.79      0.78      0.79       138\n",
      "\n",
      "    accuracy                           0.93       811\n",
      "   macro avg       0.87      0.87      0.87       811\n",
      "weighted avg       0.93      0.93      0.93       811\n",
      "\n",
      "-----RandomForest------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       673\n",
      "           1       0.95      0.78      0.86       138\n",
      "\n",
      "    accuracy                           0.96       811\n",
      "   macro avg       0.95      0.89      0.92       811\n",
      "weighted avg       0.96      0.96      0.95       811\n",
      "\n",
      "-----XGBoost------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       673\n",
      "           1       0.86      0.62      0.72       138\n",
      "\n",
      "    accuracy                           0.92       811\n",
      "   macro avg       0.89      0.80      0.84       811\n",
      "weighted avg       0.92      0.92      0.91       811\n",
      "\n",
      "-----CatBoost------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       673\n",
      "           1       0.95      0.78      0.85       138\n",
      "\n",
      "    accuracy                           0.95       811\n",
      "   macro avg       0.95      0.88      0.91       811\n",
      "weighted avg       0.95      0.95      0.95       811\n",
      "\n",
      "-----MLP------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       673\n",
      "           1       0.84      0.64      0.72       138\n",
      "\n",
      "    accuracy                           0.92       811\n",
      "   macro avg       0.88      0.81      0.84       811\n",
      "weighted avg       0.91      0.92      0.91       811\n",
      "\n",
      "-----GradientBoosting------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       673\n",
      "           1       0.87      0.63      0.73       138\n",
      "\n",
      "    accuracy                           0.92       811\n",
      "   macro avg       0.90      0.81      0.84       811\n",
      "weighted avg       0.92      0.92      0.92       811\n",
      "\n",
      "-----AdaBoost------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       673\n",
      "           1       0.84      0.59      0.69       138\n",
      "\n",
      "    accuracy                           0.91       811\n",
      "   macro avg       0.88      0.79      0.82       811\n",
      "weighted avg       0.91      0.91      0.90       811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/dlpjt/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1 기본 데이터 기준 학습률\n",
    "\n",
    "# Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logistic = LogisticRegression()\n",
    "model_logistic.fit(x_train,y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print('-----Logistic------')\n",
    "print(classification_report(y_val, model_logistic.predict(x_val)))\n",
    "\n",
    "# DecisionTree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('-----DecisionTree------')\n",
    "print(classification_report(y_val, y_val_pred)) \n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc.score(x_val, y_val)  # accuracy\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('-----RandomForest------')\n",
    "print(classification_report(y_val, rfc.predict(x_val)))\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dval = xgb.DMatrix(x_val, label=y_val)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # 이진 분류\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "predictions = model.predict(dval)\n",
    "\n",
    "predictions_binary = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "print('-----XGBoost------')\n",
    "print(classification_report(y_val, predictions_binary))\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = CatBoostClassifier(verbose=False)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "print('-----CatBoost------')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "\n",
    "mlp_model.fit(x_train, y_train)\n",
    "y_val_pred = mlp_model.predict(x_val)\n",
    "\n",
    "print('-----MLP------')\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "#GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('-----GradientBoosting------')\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('-----AdaBoost------')\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (3241, 17), (5418, 17)\n",
      "-----Logistic------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81       673\n",
      "           1       0.35      0.76      0.48       138\n",
      "\n",
      "    accuracy                           0.72       811\n",
      "   macro avg       0.64      0.74      0.65       811\n",
      "weighted avg       0.84      0.72      0.75       811\n",
      "\n",
      "-----DecisionTree------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       673\n",
      "           1       0.86      0.79      0.82       138\n",
      "\n",
      "    accuracy                           0.94       811\n",
      "   macro avg       0.91      0.88      0.89       811\n",
      "weighted avg       0.94      0.94      0.94       811\n",
      "\n",
      "-----RandomForest------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       673\n",
      "           1       0.93      0.83      0.87       138\n",
      "\n",
      "    accuracy                           0.96       811\n",
      "   macro avg       0.95      0.91      0.92       811\n",
      "weighted avg       0.96      0.96      0.96       811\n",
      "\n",
      "-----XGBoost------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       673\n",
      "           1       0.61      0.89      0.73       138\n",
      "\n",
      "    accuracy                           0.89       811\n",
      "   macro avg       0.79      0.89      0.83       811\n",
      "weighted avg       0.91      0.89      0.89       811\n",
      "\n",
      "-----CatBoost------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       673\n",
      "           1       0.87      0.91      0.89       138\n",
      "\n",
      "    accuracy                           0.96       811\n",
      "   macro avg       0.92      0.94      0.93       811\n",
      "weighted avg       0.96      0.96      0.96       811\n",
      "\n",
      "-----MLP------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       673\n",
      "           1       0.58      0.87      0.70       138\n",
      "\n",
      "    accuracy                           0.87       811\n",
      "   macro avg       0.77      0.87      0.81       811\n",
      "weighted avg       0.90      0.87      0.88       811\n",
      "\n",
      "-----GradientBoosting------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       673\n",
      "           1       0.63      0.89      0.74       138\n",
      "\n",
      "    accuracy                           0.89       811\n",
      "   macro avg       0.80      0.89      0.84       811\n",
      "weighted avg       0.92      0.89      0.90       811\n",
      "\n",
      "-----AdaBoost------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91       673\n",
      "           1       0.55      0.90      0.69       138\n",
      "\n",
      "    accuracy                           0.86       811\n",
      "   macro avg       0.76      0.87      0.80       811\n",
      "weighted avg       0.90      0.86      0.87       811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/dlpjt/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1 클래스의 정확도 부족으로 오버샘플링\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "rds = RandomOverSampler(random_state=42)\n",
    "x_train_resample, y_train_resample = rds.fit_resample(x_train,y_train)\n",
    "print(f'shape : {x_train.shape}, {x_train_resample.shape}')\n",
    "\n",
    "\n",
    "# Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logistic = LogisticRegression()\n",
    "model_logistic.fit(x_train_resample,y_train_resample)\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print('-----Logistic------')\n",
    "print(classification_report(y_val, model_logistic.predict(x_val)))\n",
    "\n",
    "# DecisionTree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "model.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('-----DecisionTree------')\n",
    "print(classification_report(y_val, y_val_pred)) \n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train_resample, y_train_resample)\n",
    "rfc.score(x_val, y_val)  # accuracy\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('-----RandomForest------')\n",
    "print(classification_report(y_val, rfc.predict(x_val)))\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train_resample, label=y_train_resample)\n",
    "dval = xgb.DMatrix(x_val, label=y_val)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # 이진 분류\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "predictions = model.predict(dval)\n",
    "\n",
    "predictions_binary = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "print('-----XGBoost------')\n",
    "print(classification_report(y_val, predictions_binary))\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = CatBoostClassifier(verbose=False)\n",
    "model.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "print('-----CatBoost------')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "\n",
    "mlp_model.fit(x_train_resample, y_train_resample)\n",
    "y_val_pred = mlp_model.predict(x_val)\n",
    "\n",
    "print('-----MLP------')\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "#GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "model.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('-----GradientBoosting------')\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "model.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('-----AdaBoost------')\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# MLP 모델 설정\n",
    "model = MLPClassifier(max_iter=5000, random_state=42, tol=1e-5)  # max_iter와 tol 조정\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,)], #(20,), (10, 10)],  # 작은 네트워크 구조만 남김\n",
    "    'activation': ['relu', 'tanh'],  # 자주 사용되는 두 가지 활성화 함수\n",
    "    'solver': ['adam', 'sgd'],  # 두 가지 주요 최적화 방법\n",
    "    'alpha': [0.0001, 0.001, 0.01]  # 적절한 정규화 값으로 범위 축소\n",
    "}\n",
    "\n",
    "# 그리드 서치 설정\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# 그리드 서치 실행\n",
    "grid_search.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "# 최적의 파라미터 및 성능 출력\n",
    "print(\"최적의 파라미터:\", grid_search.best_params_)\n",
    "print(\"최고 정확도:\", grid_search.best_score_)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = grid_search.predict(x_val)\n",
    "\n",
    "# 성능 평가\n",
    "print(\"테스트 데이터 성능 보고서:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'colsample_bytree': 0.5, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 0.1, 'subsample': 0.5}\n",
      "Best Score: 0.988004313561141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       673\n",
      "           1       0.93      0.87      0.90       138\n",
      "\n",
      "    accuracy                           0.97       811\n",
      "   macro avg       0.95      0.93      0.94       811\n",
      "weighted avg       0.97      0.97      0.97       811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': [3, 5, 7, 9],  # 트리의 최대 깊이\n",
    "    'learning_rate': [0.1],  # 학습률\n",
    "    'n_estimators': [100, 200, 300],  # 부스팅 라운드 수\n",
    "    'subsample': [0.5, 0.7],  # 각 트리의 훈련에 사용되는 샘플 비율\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],  # 각 트리의 훈련에 사용되는 피처 비율\n",
    "    'gamma': [0, 0.1],  # 노드 분할에 대한 최소 손실 감소\n",
    "    'reg_alpha': [0],  # L1 정규화\n",
    "    'reg_lambda': [0.1]  # L2 정규화\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator=xgb_model, param_grid=xgb_params, scoring='accuracy', cv=5)\n",
    "xgb_grid.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "print(f'Best Parameters for XGBoost: {xgb_grid.best_params_}')\n",
    "print(f'Best Score: {xgb_grid.best_score_}')\n",
    "\n",
    "# 최적 모델로 예측 수행\n",
    "best_model = xgb_grid.best_estimator_\n",
    "predictions = best_model.predict(x_val)\n",
    "\n",
    "# 이진 예측 결과 출력\n",
    "print(classification_report(y_val, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for CatBoost: {'bagging_temperature': 0, 'border_count': 32, 'depth': 10, 'early_stopping_rounds': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n",
      "Best Score: 0.9904031782700098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       673\n",
      "           1       0.92      0.86      0.89       138\n",
      "\n",
      "    accuracy                           0.96       811\n",
      "   macro avg       0.95      0.92      0.93       811\n",
      "weighted avg       0.96      0.96      0.96       811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': [100, 200, 500],  # 학습 반복 수\n",
    "    'depth': [3, 5, 7, 10],  # 트리의 깊이\n",
    "    'learning_rate': [0.1, 0.3],  # 학습률\n",
    "    'l2_leaf_reg': [1, 3, 5],  # L2 정규화\n",
    "    'border_count': [32, 64],  # 경계 수\n",
    "    'bagging_temperature': [0, 0.5, 1],  # 배깅 온도\n",
    "    'early_stopping_rounds': [10]  # 조기 중단 라운드 수\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_model = CatBoostClassifier(verbose=False)\n",
    "\n",
    "cat_grid = GridSearchCV(estimator=cat_model, param_grid=cat_params, scoring='accuracy', cv=5)\n",
    "cat_grid.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "print(f'Best Parameters for CatBoost: {cat_grid.best_params_}')\n",
    "print(f'Best Score: {cat_grid.best_score_}')\n",
    "\n",
    "# 최적 모델로 예측 수행\n",
    "best_model = cat_grid.best_estimator_\n",
    "predictions = best_model.predict(x_val)\n",
    "\n",
    "# 이진 예측 결과 출력\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomforest\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],            # 결정 트리의 수\n",
    "    'max_depth': [None, 10, 20, 30],           # 트리의 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10],           # 노드를 분할하는 데 필요한 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 2, 4],             # 리프 노드에 필요한 최소 샘플 수\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # 최적의 분할을 찾기 위해 고려할 특성 수\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',  # 평가 지표\n",
    "                           cv=5,                # 5-폴드 교차 검증\n",
    "                           verbose=2,          # 출력 레벨\n",
    "                           n_jobs=-1)          # 모든 CPU 사용\n",
    "\n",
    "# GridSearchCV 훈련\n",
    "grid_search.fit(x_train_resample, y_train_resample)\n",
    "\n",
    "# 최적의 하이퍼파라미터 및 교차 검증 점수 출력\n",
    "print(\"최적의 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(\"최고의 교차 검증 점수:\", grid_search.best_score_)\n",
    "\n",
    "# 최적 모델로 검증 데이터 평가\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_val)\n",
    "\n",
    "# 분류 보고서 출력\n",
    "print(\"검증 데이터에 대한 분류 보고서:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 라벨 인코딩 및 scaler inverse\n",
    "\n",
    "# 예시: 복원\n",
    "# 복원할 데이터프레임 생성 (예: 인코딩된 데이터)\n",
    "encoded_values = df[['PreferredLoginDevice', 'PreferredPaymentMode']].head(5)\n",
    "\n",
    "# 복원\n",
    "for col, encoder in label_encoders.items():\n",
    "    if col in encoded_values.columns:\n",
    "        encoded_values[col] = encoder.inverse_transform(encoded_values[col])\n",
    "\n",
    "print(encoded_values)\n",
    "# 예시: 복원\n",
    "# 복원할 데이터프레임 생성 (예: 스케일된 데이터)\n",
    "scaled_values = df[numeric_columns].head(5)\n",
    "\n",
    "# 복원\n",
    "for col in numeric_columns:\n",
    "    if col in scalers:\n",
    "        scaled_values[col] = scalers[col].inverse_transform(scaled_values[[col]])  # DataFrame 형식으로 전달\n",
    "\n",
    "print(scaled_values) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlpjt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
